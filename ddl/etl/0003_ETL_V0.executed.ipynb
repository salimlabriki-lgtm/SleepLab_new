{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7feaf86f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T08:42:46.208826Z",
     "iopub.status.busy": "2025-12-17T08:42:46.208526Z",
     "iopub.status.idle": "2025-12-17T08:42:47.271797Z",
     "shell.execute_reply": "2025-12-17T08:42:47.263185Z"
    },
    "papermill": {
     "duration": 1.072817,
     "end_time": "2025-12-17T08:42:47.276966",
     "exception": false,
     "start_time": "2025-12-17T08:42:46.204149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,276 [INFO] sleeplab_etl_luna - DB_DSN utilisé : postgresql://sleeplab:sleeplab@localhost:5432/sleeplab\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,298 [INFO] sleeplab_etl_luna - [OK] JSON LUNA LUNA trouvé : /workspaces/SleepLab_new/data/raw/MODELS_OUTPUT/predictions_luna_S0001.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,304 [INFO] sleeplab_etl_luna - Suffixe subject/session détecté à partir du nom de fichier : S0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,310 [INFO] sleeplab_etl_luna - === ETL LUNA démarré pour predictions_luna_S0001.json ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,388 [INFO] sleeplab_etl_luna - Traitement de la clé EDF : PANDORE_SAS_DATASET_S0001_PSG.edf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,392 [INFO] sleeplab_etl_luna - session_code dérivé de la clé EDF : PANDORE_SAS_DATASET_S0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:46,407 [INFO] sleeplab_etl_luna - Nouveau run AI inséré : run_id=c0ea9467-461d-4f90-8b10-7edd299d2de3 (model=LUNA, version=None, session_id=902f9f18-3ff8-47e9-a357-b5ea9a097e34)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,199 [INFO] sleeplab_etl_luna - LUNA : 1245 prédiction(s) epoch insérées pour run_id=c0ea9467-461d-4f90-8b10-7edd299d2de3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,228 [INFO] sleeplab_etl_luna - === ETL LUNA terminé pour predictions_luna_S0001.json : runs=1, epochs=1245 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,246 [INFO] sleeplab_etl_luna - LUNA : 1 run(s) créés/mis à jour, 1245 epochs insérés\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,248 [INFO] sleeplab_etl_luna - Table ai_model_run : 3 ligne(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,250 [INFO] sleeplab_etl_luna - Table ai_epoch_prediction : 3735 ligne(s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,252 [INFO] sleeplab_etl_luna - Sample ai_model_run(last_run) : [RealDictRow({'run_id': 'c0ea9467-461d-4f90-8b10-7edd299d2de3', 'session_id': '902f9f18-3ff8-47e9-a357-b5ea9a097e34', 'model_name': 'LUNA', 'model_version': None, 'training_tag': None, 'source_file_name': 'predictions_luna_S0001.json', 'params_json': {'notes': 'LUNA predictions imported from JSON (argmax over probabilities)', 'model_info': {'chs': [{'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 1, 'range': 1.0, 'scanno': 1, 'ch_name': 'Activity', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 2, 'range': 1.0, 'scanno': 2, 'ch_name': 'C3-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 3, 'range': 1.0, 'scanno': 3, 'ch_name': 'C3', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 4, 'range': 1.0, 'scanno': 4, 'ch_name': 'C4-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 5, 'range': 1.0, 'scanno': 5, 'ch_name': 'C4', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 6, 'range': 1.0, 'scanno': 6, 'ch_name': 'F3-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 7, 'range': 1.0, 'scanno': 7, 'ch_name': 'F3', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 8, 'range': 1.0, 'scanno': 8, 'ch_name': 'F4-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 9, 'range': 1.0, 'scanno': 9, 'ch_name': 'F4', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 10, 'range': 1.0, 'scanno': 10, 'ch_name': 'M1M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 11, 'range': 1.0, 'scanno': 11, 'ch_name': 'M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 12, 'range': 1.0, 'scanno': 12, 'ch_name': 'M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 13, 'range': 1.0, 'scanno': 13, 'ch_name': 'O1-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 14, 'range': 1.0, 'scanno': 14, 'ch_name': 'O1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 15, 'range': 1.0, 'scanno': 15, 'ch_name': 'O2-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 16, 'range': 1.0, 'scanno': 16, 'ch_name': 'O2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 17, 'range': 1.0, 'scanno': 17, 'ch_name': '1-2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 18, 'range': 1.0, 'scanno': 18, 'ch_name': '1-F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 19, 'range': 1.0, 'scanno': 19, 'ch_name': '1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 20, 'range': 1.0, 'scanno': 20, 'ch_name': '2-F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 21, 'range': 1.0, 'scanno': 21, 'ch_name': '2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 22, 'range': 1.0, 'scanno': 22, 'ch_name': 'F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 23, 'range': 1.0, 'scanno': 23, 'ch_name': 'Left Leg', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 24, 'range': 1.0, 'scanno': 24, 'ch_name': 'Right Leg', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 25, 'range': 1.0, 'scanno': 25, 'ch_name': 'E1-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 26, 'range': 1.0, 'scanno': 26, 'ch_name': 'E1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 27, 'range': 1.0, 'scanno': 27, 'ch_name': 'E2-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 28, 'range': 1.0, 'scanno': 28, 'ch_name': 'E2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 29, 'range': 1.0, 'scanno': 29, 'ch_name': 'Heart Rate', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 30, 'range': 1.0, 'scanno': 30, 'ch_name': 'Light', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 31, 'range': 1.0, 'scanno': 31, 'ch_name': 'PosAngle', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 32, 'range': 1.0, 'scanno': 32, 'ch_name': 'Pulse', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 33, 'range': 1.0, 'scanno': 33, 'ch_name': 'Flow Limitation', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 34, 'range': 1.0, 'scanno': 34, 'ch_name': 'Airflow', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 35, 'range': 1.0, 'scanno': 35, 'ch_name': 'RIP Flow', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 36, 'range': 1.0, 'scanno': 36, 'ch_name': 'RIP Flow Cal', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 37, 'range': 1.0, 'scanno': 37, 'ch_name': 'Inductance Abdom', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 38, 'range': 1.0, 'scanno': 38, 'ch_name': 'Inductance Thora', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 39, 'range': 1.0, 'scanno': 39, 'ch_name': 'K', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 40, 'range': 1.0, 'scanno': 40, 'ch_name': 'Abdomen RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 41, 'range': 1.0, 'scanno': 41, 'ch_name': 'Thorax RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 42, 'range': 1.0, 'scanno': 42, 'ch_name': 'Phase RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 43, 'range': 1.0, 'scanno': 43, 'ch_name': 'Nasal Pressure', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 44, 'range': 1.0, 'scanno': 44, 'ch_name': 'Resp Rate', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 45, 'range': 1.0, 'scanno': 45, 'ch_name': 'Snoring', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}], 'dig': None, 'bads': [], 'comps': [], 'nchan': 45, 'projs': [], 'sfreq': 200.0, 'events': [], 'file_id': None, 'lowpass': 100.0, 'meas_id': None, 'proj_id': None, 'acq_pars': None, 'acq_stim': None, 'ch_names': ['Activity', 'C3-M2', 'C3', 'C4-M1', 'C4', 'F3-M2', 'F3', 'F4-M1', 'F4', 'M1M2', 'M1', 'M2', 'O1-M2', 'O1', 'O2-M1', 'O2', '1-2', '1-F', '1', '2-F', '2', 'F', 'Left Leg', 'Right Leg', 'E1-M2', 'E1', 'E2-M1', 'E2', 'Heart Rate', 'Light', 'PosAngle', 'Pulse', 'Flow Limitation', 'Airflow', 'RIP Flow', 'RIP Flow Cal', 'Inductance Abdom', 'Inductance Thora', 'K', 'Abdomen RIP', 'Thorax RIP', 'Phase RIP', 'Nasal Pressure', 'Resp Rate', 'Snoring'], 'highpass': 0.0, 'hpi_meas': [], 'dev_ctf_t': None, 'line_freq': None, 'meas_date': '2001-01-01T22:00:08+00:00', 'proj_name': None, 'ctf_head_t': None, 'dev_head_t': None, 'utc_offset': None, 'description': None, 'device_info': None, 'helium_info': None, 'hpi_results': [], 'experimenter': None, 'gantry_angle': None, 'proc_history': [], 'subject_info': {'sex': 0, 'his_id': 'X', 'last_name': 'X'}, 'hpi_subsystem': None, 'kit_system_id': None, 'xplotter_layout': None, 'custom_ref_applied': 0}, 'used_channel': {'eeg_channel': ['F3-M2']}, 'source_edf_key': 'PANDORE_SAS_DATASET_S0001_PSG.edf'}, 'run_ts': datetime.datetime(2025, 12, 17, 8, 42, 46, 393279, tzinfo=datetime.timezone.utc), 'created_ts': datetime.datetime(2025, 12, 17, 8, 42, 46, 393279, tzinfo=datetime.timezone.utc)})]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-17 08:42:47,255 [INFO] sleeplab_etl_luna - Sample ai_epoch_prediction(last_run, 10 premiers) : [RealDictRow({'epoch_index': 0, 'onset_sec': Decimal('0.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99707'), 'prob_n1': Decimal('0.00120'), 'prob_n2': Decimal('0.00120'), 'prob_n3': Decimal('0.00029'), 'prob_r': Decimal('0.00024')}), RealDictRow({'epoch_index': 1, 'onset_sec': Decimal('30.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99559'), 'prob_n1': Decimal('0.00278'), 'prob_n2': Decimal('0.00121'), 'prob_n3': Decimal('0.00012'), 'prob_r': Decimal('0.00030')}), RealDictRow({'epoch_index': 2, 'onset_sec': Decimal('60.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99732'), 'prob_n1': Decimal('0.00163'), 'prob_n2': Decimal('0.00073'), 'prob_n3': Decimal('0.00008'), 'prob_r': Decimal('0.00025')}), RealDictRow({'epoch_index': 3, 'onset_sec': Decimal('90.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99595'), 'prob_n1': Decimal('0.00231'), 'prob_n2': Decimal('0.00124'), 'prob_n3': Decimal('0.00012'), 'prob_r': Decimal('0.00037')}), RealDictRow({'epoch_index': 4, 'onset_sec': Decimal('120.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99433'), 'prob_n1': Decimal('0.00401'), 'prob_n2': Decimal('0.00116'), 'prob_n3': Decimal('0.00011'), 'prob_r': Decimal('0.00039')}), RealDictRow({'epoch_index': 5, 'onset_sec': Decimal('150.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99162'), 'prob_n1': Decimal('0.00631'), 'prob_n2': Decimal('0.00142'), 'prob_n3': Decimal('0.00016'), 'prob_r': Decimal('0.00050')}), RealDictRow({'epoch_index': 6, 'onset_sec': Decimal('180.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99309'), 'prob_n1': Decimal('0.00460'), 'prob_n2': Decimal('0.00164'), 'prob_n3': Decimal('0.00017'), 'prob_r': Decimal('0.00050')}), RealDictRow({'epoch_index': 7, 'onset_sec': Decimal('210.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99392'), 'prob_n1': Decimal('0.00412'), 'prob_n2': Decimal('0.00142'), 'prob_n3': Decimal('0.00013'), 'prob_r': Decimal('0.00039')}), RealDictRow({'epoch_index': 8, 'onset_sec': Decimal('240.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99041'), 'prob_n1': Decimal('0.00785'), 'prob_n2': Decimal('0.00114'), 'prob_n3': Decimal('0.00012'), 'prob_r': Decimal('0.00049')}), RealDictRow({'epoch_index': 9, 'onset_sec': Decimal('270.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W', 'prob_w': Decimal('0.99204'), 'prob_n1': Decimal('0.00633'), 'prob_n2': Decimal('0.00111'), 'prob_n3': Decimal('0.00011'), 'prob_r': Decimal('0.00042')})]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0006_OUTPUT_LUNA_INTEGRATION.py\n",
    "# ETL des prédictions LUNA vers les tables AI\n",
    "# (ai_model_run + ai_epoch_prediction)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Logging\n",
    "# ------------------------------------------------------------\n",
    "logger = logging.getLogger(\"sleeplab_etl_luna\")\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "    )\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Config chemins & Postgres\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = Path(\"/workspaces/SleepLab_new\").resolve()\n",
    "MODELS_OUTPUT_DIR = BASE_DIR / \"data\" / \"raw\" / \"MODELS_OUTPUT\"\n",
    "\n",
    "DEFAULT_LUNA_JSON = MODELS_OUTPUT_DIR / \"predictions_luna_S0001.json\"\n",
    "\n",
    "DB_DSN = os.getenv(\n",
    "    \"SLEEPLAB_DB_DSN\",\n",
    "    \"postgresql://sleeplab:sleeplab@postgres:5432/sleeplab\",\n",
    ")\n",
    "logger.info(\"DB_DSN utilisé : %s\", DB_DSN)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Helpers Postgres\n",
    "# ------------------------------------------------------------\n",
    "def get_conn():\n",
    "    conn = psycopg2.connect(DB_DSN)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SET search_path TO sleeplab\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "\n",
    "def db_cursor(conn, dict_cursor: bool = False):\n",
    "    cursor_factory = RealDictCursor if dict_cursor else None\n",
    "    return conn.cursor(cursor_factory=cursor_factory)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Helpers métier : mapping session / run\n",
    "# ------------------------------------------------------------\n",
    "def require_file(path: Path, label: str) -> None:\n",
    "    if not path.exists():\n",
    "        logger.error(\"[FICHIER MANQUANT] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} non trouvé : {path}\")\n",
    "    if not path.is_file():\n",
    "        logger.error(\"[CHEMIN NON FICHIER] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} n'est pas un fichier : {path}\")\n",
    "    logger.info(\"[OK] %s trouvé : %s\", label, path)\n",
    "\n",
    "\n",
    "def extract_subject_suffix_from_filename(json_path: Path) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Ex: 'predictions_luna_S0001.json' -> 'S0001'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"_S(\\d{4})\\.json$\", json_path.name, re.IGNORECASE)\n",
    "    if not m:\n",
    "        logger.warning(\n",
    "            \"Impossible d'extraire un suffixe 'Sdddd' depuis le nom de fichier %s\",\n",
    "            json_path.name,\n",
    "        )\n",
    "        return None\n",
    "    suffix = f\"S{m.group(1)}\"\n",
    "    logger.info(\"Suffixe subject/session détecté à partir du nom de fichier : %s\", suffix)\n",
    "    return suffix\n",
    "\n",
    "\n",
    "def extract_session_code_from_edf_key(edf_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Ex: 'PANDORE_SAS_DATASET_S0001_PSG.edf' -> 'PANDORE_SAS_DATASET_S0001'\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^(?P<session_root>.+_S\\d{4})_PSG\\.edf$\", edf_key)\n",
    "    if not m:\n",
    "        raise ValueError(\n",
    "            f\"Impossible d'extraire session_root depuis la clé EDF '{edf_key}'\"\n",
    "        )\n",
    "    return m.group(\"session_root\")\n",
    "\n",
    "\n",
    "def get_session_id_from_code(conn, session_code: str) -> str:\n",
    "    with db_cursor(conn, dict_cursor=True) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT session_id\n",
    "            FROM study_session\n",
    "            WHERE session_code = %s\n",
    "            \"\"\",\n",
    "            (session_code,),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            raise RuntimeError(\n",
    "                f\"Aucune session trouvée pour session_code={session_code}\"\n",
    "            )\n",
    "        return row[\"session_id\"]\n",
    "\n",
    "\n",
    "def get_or_create_ai_model_run(\n",
    "    conn,\n",
    "    session_id: str,\n",
    "    model_name: str,\n",
    "    model_version: Optional[str],\n",
    "    training_tag: Optional[str],\n",
    "    source_file_name: str,\n",
    "    params_json: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    version_key = model_version or \"\"\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT run_id\n",
    "            FROM ai_model_run\n",
    "            WHERE session_id = %s\n",
    "              AND model_name = %s\n",
    "              AND COALESCE(model_version,'') = %s\n",
    "              AND source_file_name = %s\n",
    "            \"\"\",\n",
    "            (session_id, model_name, version_key, source_file_name),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            run_id = row[0]\n",
    "            logger.info(\n",
    "                \"Run AI déjà présent (session_id=%s, model=%s, version=%s, src=%s) → run_id=%s\",\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                source_file_name,\n",
    "                run_id,\n",
    "            )\n",
    "            return run_id\n",
    "\n",
    "        run_id = str(uuid.uuid4())\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO ai_model_run (\n",
    "                run_id, session_id,\n",
    "                model_name, model_version,\n",
    "                training_tag, source_file_name,\n",
    "                params_json, created_ts\n",
    "            )\n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s, NOW())\n",
    "            \"\"\",\n",
    "            (\n",
    "                run_id,\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                training_tag,\n",
    "                source_file_name,\n",
    "                json.dumps(params_json) if params_json is not None else None,\n",
    "            ),\n",
    "        )\n",
    "        logger.info(\n",
    "            \"Nouveau run AI inséré : run_id=%s (model=%s, version=%s, session_id=%s)\",\n",
    "            run_id,\n",
    "            model_name,\n",
    "            model_version,\n",
    "            session_id,\n",
    "        )\n",
    "        return run_id\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Mapping LUNA -> stage\n",
    "# ------------------------------------------------------------\n",
    "LUNA_STAGE_KEYS = [\n",
    "    (\"W\",  \"prob_Wake\"),\n",
    "    (\"N1\", \"prob_N1\"),\n",
    "    (\"N2\", \"prob_N2\"),\n",
    "    (\"N3\", \"prob_N3\"),\n",
    "    (\"R\",  \"prob_REM\"),\n",
    "]\n",
    "\n",
    "\n",
    "def luna_pick_stage_from_probs(prob_row: Dict[str, float]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    prob_row contient: {'prob_Wake': x, 'prob_N1': y, ...}\n",
    "    Retourne le stage_code correspondant au max.\n",
    "    \"\"\"\n",
    "    best_stage = None\n",
    "    best_p = None\n",
    "    for stage_code, k in LUNA_STAGE_KEYS:\n",
    "        p = prob_row.get(k)\n",
    "        if p is None:\n",
    "            continue\n",
    "        try:\n",
    "            p = float(p)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if best_p is None or p > best_p:\n",
    "            best_p = p\n",
    "            best_stage = stage_code\n",
    "    return best_stage\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. ETL principal LUNA\n",
    "# ------------------------------------------------------------\n",
    "def etl_luna_from_json_file(\n",
    "    json_path: Path,\n",
    "    model_name: str = \"LUNA\",\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "    default_epoch_length_sec: int = 30,\n",
    ") -> Tuple[List[str], int]:\n",
    "    \"\"\"\n",
    "    Intègre un JSON LUNA dans ai_model_run + ai_epoch_prediction.\n",
    "\n",
    "    Structure attendue (par EDF) :\n",
    "      {\n",
    "        \"PANDORE_SAS_DATASET_S0001_PSG.edf\": {\n",
    "          \"infos\": {...},\n",
    "          \"used_channel\": ...,\n",
    "          \"timestamps\": [0, 30, 60, ...],\n",
    "          \"predictions\": \"{\\\"prob_Wake\\\": {\\\"1\\\":0.1,...}, \\\"prob_N1\\\": {...}, ...}\"\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    require_file(json_path, f\"JSON LUNA {model_name}\")\n",
    "    suffix = extract_subject_suffix_from_filename(json_path)\n",
    "\n",
    "    logger.info(\"=== ETL LUNA démarré pour %s ===\", json_path.name)\n",
    "    data = json.loads(json_path.read_text())\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(f\"Structure JSON inattendue (top-level) : {type(data)}\")\n",
    "\n",
    "    conn = get_conn()\n",
    "    run_ids: List[str] = []\n",
    "    total_epochs = 0\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            for edf_key, payload in data.items():\n",
    "                logger.info(\"Traitement de la clé EDF : %s\", edf_key)\n",
    "\n",
    "                session_code = extract_session_code_from_edf_key(edf_key)\n",
    "                logger.info(\"session_code dérivé de la clé EDF : %s\", session_code)\n",
    "\n",
    "                if suffix and suffix.lower() not in session_code.lower():\n",
    "                    logger.warning(\n",
    "                        \"Le suffixe '%s' (depuis le nom du fichier JSON) \"\n",
    "                        \"ne correspond pas au session_code '%s' (clé EDF).\",\n",
    "                        suffix,\n",
    "                        session_code,\n",
    "                    )\n",
    "\n",
    "                session_id = get_session_id_from_code(conn, session_code)\n",
    "\n",
    "                if not isinstance(payload, dict):\n",
    "                    logger.warning(\n",
    "                        \"Payload LUNA inattendu pour %s (type=%s) → ignoré\",\n",
    "                        edf_key,\n",
    "                        type(payload),\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                stamps = payload.get(\"timestamps\")\n",
    "                pred_str = payload.get(\"predictions\")\n",
    "\n",
    "                if stamps is None or pred_str is None:\n",
    "                    logger.warning(\n",
    "                        \"timestamps ou predictions manquants pour %s → ignoré\", edf_key\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # predictions est un JSON string -> dict\n",
    "                try:\n",
    "                    pred_dict = json.loads(pred_str) if isinstance(pred_str, str) else pred_str\n",
    "                except Exception as e:\n",
    "                    logger.error(\"Impossible de parser payload['predictions'] (json string) : %s\", e)\n",
    "                    continue\n",
    "\n",
    "                # On attend ces 5 dicts\n",
    "                missing_keys = [k for _, k in LUNA_STAGE_KEYS if k not in pred_dict]\n",
    "                if missing_keys:\n",
    "                    logger.warning(\n",
    "                        \"Clés de proba manquantes dans predictions (%s) pour %s → ignoré\",\n",
    "                        missing_keys,\n",
    "                        edf_key,\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                n = len(stamps)\n",
    "\n",
    "                infos = payload.get(\"infos\", {})\n",
    "                used_channel = payload.get(\"used_channel\")\n",
    "\n",
    "                params_json = {\n",
    "                    \"source_edf_key\": edf_key,\n",
    "                    \"model_info\": infos,\n",
    "                    \"used_channel\": used_channel,\n",
    "                    \"notes\": \"LUNA predictions imported from JSON (argmax over probabilities)\",\n",
    "                }\n",
    "\n",
    "                run_id = get_or_create_ai_model_run(\n",
    "                    conn,\n",
    "                    session_id=session_id,\n",
    "                    model_name=model_name,\n",
    "                    model_version=model_version,\n",
    "                    training_tag=training_tag,\n",
    "                    source_file_name=json_path.name,\n",
    "                    params_json=params_json,\n",
    "                )\n",
    "                run_ids.append(run_id)\n",
    "\n",
    "                # Nettoyage préalable (idempotence)\n",
    "                with db_cursor(conn) as cur:\n",
    "                    cur.execute(\n",
    "                        \"DELETE FROM ai_epoch_prediction WHERE run_id = %s\",\n",
    "                        (run_id,),\n",
    "                    )\n",
    "                    nb_deleted = cur.rowcount\n",
    "                if nb_deleted:\n",
    "                    logger.info(\n",
    "                        \"%d prédiction(s) LUNA existante(s) supprimée(s) pour run_id=%s\",\n",
    "                        nb_deleted,\n",
    "                        run_id,\n",
    "                    )\n",
    "\n",
    "                # Insertion\n",
    "                inserted = 0\n",
    "                with db_cursor(conn) as cur:\n",
    "                    for idx in range(n):\n",
    "                        # timestamps (onset_sec)\n",
    "                        ts = stamps[idx]\n",
    "                        try:\n",
    "                            onset_sec = float(ts)\n",
    "                        except Exception:\n",
    "                            onset_sec = float(idx * default_epoch_length_sec)\n",
    "\n",
    "                        # duration\n",
    "                        if idx < n - 1:\n",
    "                            try:\n",
    "                                duration_sec = float(stamps[idx + 1]) - float(ts)\n",
    "                            except Exception:\n",
    "                                duration_sec = float(default_epoch_length_sec)\n",
    "                        else:\n",
    "                            duration_sec = float(default_epoch_length_sec)\n",
    "\n",
    "                        # LUNA probas sont indexées en \"1..N\"\n",
    "                        key1 = str(idx + 1)\n",
    "\n",
    "                        def _get_prob(prob_key: str) -> Optional[float]:\n",
    "                            d = pred_dict.get(prob_key) or {}\n",
    "                            v = d.get(key1)\n",
    "                            if v is None:\n",
    "                                return None\n",
    "                            try:\n",
    "                                return float(v)\n",
    "                            except Exception:\n",
    "                                return None\n",
    "\n",
    "                        prob_w  = _get_prob(\"prob_Wake\")\n",
    "                        prob_n1 = _get_prob(\"prob_N1\")\n",
    "                        prob_n2 = _get_prob(\"prob_N2\")\n",
    "                        prob_n3 = _get_prob(\"prob_N3\")\n",
    "                        prob_r  = _get_prob(\"prob_REM\")\n",
    "\n",
    "                        prob_row = {\n",
    "                            \"prob_Wake\": prob_w,\n",
    "                            \"prob_N1\": prob_n1,\n",
    "                            \"prob_N2\": prob_n2,\n",
    "                            \"prob_N3\": prob_n3,\n",
    "                            \"prob_REM\": prob_r,\n",
    "                        }\n",
    "                        stage = luna_pick_stage_from_probs(prob_row)\n",
    "\n",
    "                        extra_json = {\n",
    "                            \"luna_epoch_key\": key1,\n",
    "                            \"timestamp_raw\": ts,\n",
    "                            \"used_channel\": used_channel,\n",
    "                        }\n",
    "\n",
    "                        epoch_pred_id = str(uuid.uuid4())\n",
    "                        cur.execute(\n",
    "                            \"\"\"\n",
    "                            INSERT INTO ai_epoch_prediction (\n",
    "                                epoch_pred_id, run_id,\n",
    "                                epoch_index, onset_sec, duration_sec,\n",
    "                                predicted_stage_code,\n",
    "                                prob_w, prob_n1, prob_n2, prob_n3, prob_r,\n",
    "                                extra_json\n",
    "                            )\n",
    "                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                            \"\"\",\n",
    "                            (\n",
    "                                epoch_pred_id,\n",
    "                                run_id,\n",
    "                                int(idx),\n",
    "                                onset_sec,\n",
    "                                duration_sec,\n",
    "                                stage,\n",
    "                                prob_w,\n",
    "                                prob_n1,\n",
    "                                prob_n2,\n",
    "                                prob_n3,\n",
    "                                prob_r,\n",
    "                                json.dumps(extra_json),\n",
    "                            ),\n",
    "                        )\n",
    "                        inserted += 1\n",
    "\n",
    "                logger.info(\n",
    "                    \"LUNA : %d prédiction(s) epoch insérées pour run_id=%s\",\n",
    "                    inserted,\n",
    "                    run_id,\n",
    "                )\n",
    "                total_epochs += inserted\n",
    "\n",
    "        logger.info(\n",
    "            \"=== ETL LUNA terminé pour %s : runs=%d, epochs=%d ===\",\n",
    "            json_path.name,\n",
    "            len(run_ids),\n",
    "            total_epochs,\n",
    "        )\n",
    "        return run_ids, total_epochs\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Run checks\n",
    "# ------------------------------------------------------------\n",
    "def log_table_count(conn, table: str):\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        nb = cur.fetchone()[0]\n",
    "    logger.info(\"Table %s : %d ligne(s)\", table, nb)\n",
    "\n",
    "\n",
    "def run_checks_after_etl_luna(\n",
    "    json_path: Path,\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "):\n",
    "    run_ids, total_epochs = etl_luna_from_json_file(\n",
    "        json_path=json_path,\n",
    "        model_version=model_version,\n",
    "        training_tag=training_tag,\n",
    "    )\n",
    "\n",
    "    conn = get_conn()\n",
    "    try:\n",
    "        logger.info(\n",
    "            \"LUNA : %d run(s) créés/mis à jour, %d epochs insérés\",\n",
    "            len(run_ids),\n",
    "            total_epochs,\n",
    "        )\n",
    "\n",
    "        for tbl in [\"ai_model_run\", \"ai_epoch_prediction\"]:\n",
    "            log_table_count(conn, tbl)\n",
    "\n",
    "        if run_ids:\n",
    "            last_run = run_ids[-1]\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT *\n",
    "                    FROM ai_model_run\n",
    "                    WHERE run_id = %s\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\"Sample ai_model_run(last_run) : %s\", cur.fetchall())\n",
    "\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT epoch_index, onset_sec, duration_sec,\n",
    "                           predicted_stage_code,\n",
    "                           prob_w, prob_n1, prob_n2, prob_n3, prob_r\n",
    "                    FROM ai_epoch_prediction\n",
    "                    WHERE run_id = %s\n",
    "                    ORDER BY epoch_index\n",
    "                    LIMIT 10\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Sample ai_epoch_prediction(last_run, 10 premiers) : %s\",\n",
    "                    cur.fetchall(),\n",
    "                )\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Par défaut: predictions_luna_S0001.json\n",
    "    run_checks_after_etl_luna(DEFAULT_LUNA_JSON)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_sleeplab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3.311301,
   "end_time": "2025-12-17T08:42:47.597606",
   "environment_variables": {},
   "exception": null,
   "input_path": "/workspaces/SleepLab_new/ddl/etl/0006_OUTPUT_LUNA_INTEGRATION.ipynb",
   "output_path": "ddl/etl/0003_ETL_V0.executed.ipynb",
   "parameters": {},
   "start_time": "2025-12-17T08:42:44.286305",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}