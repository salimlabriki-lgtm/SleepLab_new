

{
z "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feaf86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0006_OUTPUT_LUNA_INTEGRATION.py\n",
    "# ETL des prédictions LUNA vers les tables AI\n",
    "# (ai_model_run + ai_epoch_prediction)\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Logging\n",
    "# ------------------------------------------------------------\n",
    "logger = logging.getLogger(\"sleeplab_etl_luna\")\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "    )\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Config chemins & Postgres\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = Path(\"/workspaces/SleepLab_new\").resolve()\n",
    "MODELS_OUTPUT_DIR = BASE_DIR / \"data\" / \"raw\" / \"MODELS_OUTPUT\"\n",
    "\n",
    "DEFAULT_LUNA_JSON = MODELS_OUTPUT_DIR / \"predictions_luna_S0001.json\"\n",
    "\n",
    "DB_DSN = os.getenv(\n",
    "    \"SLEEPLAB_DB_DSN\",\n",
    "    \"postgresql://sleeplab:sleeplab@postgres:5432/sleeplab\",\n",
    ")\n",
    "logger.info(\"DB_DSN utilisé : %s\", DB_DSN)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Helpers Postgres\n",
    "# ------------------------------------------------------------\n",
    "def get_conn():\n",
    "    conn = psycopg2.connect(DB_DSN)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SET search_path TO sleeplab\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "\n",
    "def db_cursor(conn, dict_cursor: bool = False):\n",
    "    cursor_factory = RealDictCursor if dict_cursor else None\n",
    "    return conn.cursor(cursor_factory=cursor_factory)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Helpers métier : mapping session / run\n",
    "# ------------------------------------------------------------\n",
    "def require_file(path: Path, label: str) -> None:\n",
    "    if not path.exists():\n",
    "        logger.error(\"[FICHIER MANQUANT] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} non trouvé : {path}\")\n",
    "    if not path.is_file():\n",
    "        logger.error(\"[CHEMIN NON FICHIER] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} n'est pas un fichier : {path}\")\n",
    "    logger.info(\"[OK] %s trouvé : %s\", label, path)\n",
    "\n",
    "\n",
    "def extract_subject_suffix_from_filename(json_path: Path) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Ex: 'predictions_luna_S0001.json' -> 'S0001'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"_S(\\d{4})\\.json$\", json_path.name, re.IGNORECASE)\n",
    "    if not m:\n",
    "        logger.warning(\n",
    "            \"Impossible d'extraire un suffixe 'Sdddd' depuis le nom de fichier %s\",\n",
    "            json_path.name,\n",
    "        )\n",
    "        return None\n",
    "    suffix = f\"S{m.group(1)}\"\n",
    "    logger.info(\"Suffixe subject/session détecté à partir du nom de fichier : %s\", suffix)\n",
    "    return suffix\n",
    "\n",
    "\n",
    "def extract_session_code_from_edf_key(edf_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Ex: 'PANDORE_SAS_DATASET_S0001_PSG.edf' -> 'PANDORE_SAS_DATASET_S0001'\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^(?P<session_root>.+_S\\d{4})_PSG\\.edf$\", edf_key)\n",
    "    if not m:\n",
    "        raise ValueError(\n",
    "            f\"Impossible d'extraire session_root depuis la clé EDF '{edf_key}'\"\n",
    "        )\n",
    "    return m.group(\"session_root\")\n",
    "\n",
    "\n",
    "def get_session_id_from_code(conn, session_code: str) -> str:\n",
    "    with db_cursor(conn, dict_cursor=True) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT session_id\n",
    "            FROM study_session\n",
    "            WHERE session_code = %s\n",
    "            \"\"\",\n",
    "            (session_code,),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            raise RuntimeError(\n",
    "                f\"Aucune session trouvée pour session_code={session_code}\"\n",
    "            )\n",
    "        return row[\"session_id\"]\n",
    "\n",
    "\n",
    "def get_or_create_ai_model_run(\n",
    "    conn,\n",
    "    session_id: str,\n",
    "    model_name: str,\n",
    "    model_version: Optional[str],\n",
    "    training_tag: Optional[str],\n",
    "    source_file_name: str,\n",
    "    params_json: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    version_key = model_version or \"\"\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT run_id\n",
    "            FROM ai_model_run\n",
    "            WHERE session_id = %s\n",
    "              AND model_name = %s\n",
    "              AND COALESCE(model_version,'') = %s\n",
    "              AND source_file_name = %s\n",
    "            \"\"\",\n",
    "            (session_id, model_name, version_key, source_file_name),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            run_id = row[0]\n",
    "            logger.info(\n",
    "                \"Run AI déjà présent (session_id=%s, model=%s, version=%s, src=%s) → run_id=%s\",\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                source_file_name,\n",
    "                run_id,\n",
    "            )\n",
    "            return run_id\n",
    "\n",
    "        run_id = str(uuid.uuid4())\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO ai_model_run (\n",
    "                run_id, session_id,\n",
    "                model_name, model_version,\n",
    "                training_tag, source_file_name,\n",
    "                params_json, created_ts\n",
    "            )\n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s, NOW())\n",
    "            \"\"\",\n",
    "            (\n",
    "                run_id,\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                training_tag,\n",
    "                source_file_name,\n",
    "                json.dumps(params_json) if params_json is not None else None,\n",
    "            ),\n",
    "        )\n",
    "        logger.info(\n",
    "            \"Nouveau run AI inséré : run_id=%s (model=%s, version=%s, session_id=%s)\",\n",
    "            run_id,\n",
    "            model_name,\n",
    "            model_version,\n",
    "            session_id,\n",
    "        )\n",
    "        return run_id\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Mapping LUNA -> stage\n",
    "# ------------------------------------------------------------\n",
    "LUNA_STAGE_KEYS = [\n",
    "    (\"W\",  \"prob_Wake\"),\n",
    "    (\"N1\", \"prob_N1\"),\n",
    "    (\"N2\", \"prob_N2\"),\n",
    "    (\"N3\", \"prob_N3\"),\n",
    "    (\"R\",  \"prob_REM\"),\n",
    "]\n",
    "\n",
    "\n",
    "def luna_pick_stage_from_probs(prob_row: Dict[str, float]) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    prob_row contient: {'prob_Wake': x, 'prob_N1': y, ...}\n",
    "    Retourne le stage_code correspondant au max.\n",
    "    \"\"\"\n",
    "    best_stage = None\n",
    "    best_p = None\n",
    "    for stage_code, k in LUNA_STAGE_KEYS:\n",
    "        p = prob_row.get(k)\n",
    "        if p is None:\n",
    "            continue\n",
    "        try:\n",
    "            p = float(p)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if best_p is None or p > best_p:\n",
    "            best_p = p\n",
    "            best_stage = stage_code\n",
    "    return best_stage\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. ETL principal LUNA\n",
    "# ------------------------------------------------------------\n",
    "def etl_luna_from_json_file(\n",
    "    json_path: Path,\n",
    "    model_name: str = \"LUNA\",\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "    default_epoch_length_sec: int = 30,\n",
    ") -> Tuple[List[str], int]:\n",
    "    \"\"\"\n",
    "    Intègre un JSON LUNA dans ai_model_run + ai_epoch_prediction.\n",
    "\n",
    "    Structure attendue (par EDF) :\n",
    "      {\n",
    "        \"PANDORE_SAS_DATASET_S0001_PSG.edf\": {\n",
    "          \"infos\": {...},\n",
    "          \"used_channel\": ...,\n",
    "          \"timestamps\": [0, 30, 60, ...],\n",
    "          \"predictions\": \"{\\\"prob_Wake\\\": {\\\"1\\\":0.1,...}, \\\"prob_N1\\\": {...}, ...}\"\n",
    "        }\n",
    "      }\n",
    "    \"\"\"\n",
    "    require_file(json_path, f\"JSON LUNA {model_name}\")\n",
    "    suffix = extract_subject_suffix_from_filename(json_path)\n",
    "\n",
    "    logger.info(\"=== ETL LUNA démarré pour %s ===\", json_path.name)\n",
    "    data = json.loads(json_path.read_text())\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(f\"Structure JSON inattendue (top-level) : {type(data)}\")\n",
    "\n",
    "    conn = get_conn()\n",
    "    run_ids: List[str] = []\n",
    "    total_epochs = 0\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            for edf_key, payload in data.items():\n",
    "                logger.info(\"Traitement de la clé EDF : %s\", edf_key)\n",
    "\n",
    "                session_code = extract_session_code_from_edf_key(edf_key)\n",
    "                logger.info(\"session_code dérivé de la clé EDF : %s\", session_code)\n",
    "\n",
    "                if suffix and suffix.lower() not in session_code.lower():\n",
    "                    logger.warning(\n",
    "                        \"Le suffixe '%s' (depuis le nom du fichier JSON) \"\n",
    "                        \"ne correspond pas au session_code '%s' (clé EDF).\",\n",
    "                        suffix,\n",
    "                        session_code,\n",
    "                    )\n",
    "\n",
    "                session_id = get_session_id_from_code(conn, session_code)\n",
    "\n",
    "                if not isinstance(payload, dict):\n",
    "                    logger.warning(\n",
    "                        \"Payload LUNA inattendu pour %s (type=%s) → ignoré\",\n",
    "                        edf_key,\n",
    "                        type(payload),\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                stamps = payload.get(\"timestamps\")\n",
    "                pred_str = payload.get(\"predictions\")\n",
    "\n",
    "                if stamps is None or pred_str is None:\n",
    "                    logger.warning(\n",
    "                        \"timestamps ou predictions manquants pour %s → ignoré\", edf_key\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                # predictions est un JSON string -> dict\n",
    "                try:\n",
    "                    pred_dict = json.loads(pred_str) if isinstance(pred_str, str) else pred_str\n",
    "                except Exception as e:\n",
    "                    logger.error(\"Impossible de parser payload['predictions'] (json string) : %s\", e)\n",
    "                    continue\n",
    "\n",
    "                # On attend ces 5 dicts\n",
    "                missing_keys = [k for _, k in LUNA_STAGE_KEYS if k not in pred_dict]\n",
    "                if missing_keys:\n",
    "                    logger.warning(\n",
    "                        \"Clés de proba manquantes dans predictions (%s) pour %s → ignoré\",\n",
    "                        missing_keys,\n",
    "                        edf_key,\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                n = len(stamps)\n",
    "\n",
    "                infos = payload.get(\"infos\", {})\n",
    "                used_channel = payload.get(\"used_channel\")\n",
    "\n",
    "                params_json = {\n",
    "                    \"source_edf_key\": edf_key,\n",
    "                    \"model_info\": infos,\n",
    "                    \"used_channel\": used_channel,\n",
    "                    \"notes\": \"LUNA predictions imported from JSON (argmax over probabilities)\",\n",
    "                }\n",
    "\n",
    "                run_id = get_or_create_ai_model_run(\n",
    "                    conn,\n",
    "                    session_id=session_id,\n",
    "                    model_name=model_name,\n",
    "                    model_version=model_version,\n",
    "                    training_tag=training_tag,\n",
    "                    source_file_name=json_path.name,\n",
    "                    params_json=params_json,\n",
    "                )\n",
    "                run_ids.append(run_id)\n",
    "\n",
    "                # Nettoyage préalable (idempotence)\n",
    "                with db_cursor(conn) as cur:\n",
    "                    cur.execute(\n",
    "                        \"DELETE FROM ai_epoch_prediction WHERE run_id = %s\",\n",
    "                        (run_id,),\n",
    "                    )\n",
    "                    nb_deleted = cur.rowcount\n",
    "                if nb_deleted:\n",
    "                    logger.info(\n",
    "                        \"%d prédiction(s) LUNA existante(s) supprimée(s) pour run_id=%s\",\n",
    "                        nb_deleted,\n",
    "                        run_id,\n",
    "                    )\n",
    "\n",
    "                # Insertion\n",
    "                inserted = 0\n",
    "                with db_cursor(conn) as cur:\n",
    "                    for idx in range(n):\n",
    "                        # timestamps (onset_sec)\n",
    "                        ts = stamps[idx]\n",
    "                        try:\n",
    "                            onset_sec = float(ts)\n",
    "                        except Exception:\n",
    "                            onset_sec = float(idx * default_epoch_length_sec)\n",
    "\n",
    "                        # duration\n",
    "                        if idx < n - 1:\n",
    "                            try:\n",
    "                                duration_sec = float(stamps[idx + 1]) - float(ts)\n",
    "                            except Exception:\n",
    "                                duration_sec = float(default_epoch_length_sec)\n",
    "                        else:\n",
    "                            duration_sec = float(default_epoch_length_sec)\n",
    "\n",
    "                        # LUNA probas sont indexées en \"1..N\"\n",
    "                        key1 = str(idx + 1)\n",
    "\n",
    "                        def _get_prob(prob_key: str) -> Optional[float]:\n",
    "                            d = pred_dict.get(prob_key) or {}\n",
    "                            v = d.get(key1)\n",
    "                            if v is None:\n",
    "                                return None\n",
    "                            try:\n",
    "                                return float(v)\n",
    "                            except Exception:\n",
    "                                return None\n",
    "\n",
    "                        prob_w  = _get_prob(\"prob_Wake\")\n",
    "                        prob_n1 = _get_prob(\"prob_N1\")\n",
    "                        prob_n2 = _get_prob(\"prob_N2\")\n",
    "                        prob_n3 = _get_prob(\"prob_N3\")\n",
    "                        prob_r  = _get_prob(\"prob_REM\")\n",
    "\n",
    "                        prob_row = {\n",
    "                            \"prob_Wake\": prob_w,\n",
    "                            \"prob_N1\": prob_n1,\n",
    "                            \"prob_N2\": prob_n2,\n",
    "                            \"prob_N3\": prob_n3,\n",
    "                            \"prob_REM\": prob_r,\n",
    "                        }\n",
    "                        stage = luna_pick_stage_from_probs(prob_row)\n",
    "\n",
    "                        extra_json = {\n",
    "                            \"luna_epoch_key\": key1,\n",
    "                            \"timestamp_raw\": ts,\n",
    "                            \"used_channel\": used_channel,\n",
    "                        }\n",
    "\n",
    "                        epoch_pred_id = str(uuid.uuid4())\n",
    "                        cur.execute(\n",
    "                            \"\"\"\n",
    "                            INSERT INTO ai_epoch_prediction (\n",
    "                                epoch_pred_id, run_id,\n",
    "                                epoch_index, onset_sec, duration_sec,\n",
    "                                predicted_stage_code,\n",
    "                                prob_w, prob_n1, prob_n2, prob_n3, prob_r,\n",
    "                                extra_json\n",
    "                            )\n",
    "                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                            \"\"\",\n",
    "                            (\n",
    "                                epoch_pred_id,\n",
    "                                run_id,\n",
    "                                int(idx),\n",
    "                                onset_sec,\n",
    "                                duration_sec,\n",
    "                                stage,\n",
    "                                prob_w,\n",
    "                                prob_n1,\n",
    "                                prob_n2,\n",
    "                                prob_n3,\n",
    "                                prob_r,\n",
    "                                json.dumps(extra_json),\n",
    "                            ),\n",
    "                        )\n",
    "                        inserted += 1\n",
    "\n",
    "                logger.info(\n",
    "                    \"LUNA : %d prédiction(s) epoch insérées pour run_id=%s\",\n",
    "                    inserted,\n",
    "                    run_id,\n",
    "                )\n",
    "                total_epochs += inserted\n",
    "\n",
    "        logger.info(\n",
    "            \"=== ETL LUNA terminé pour %s : runs=%d, epochs=%d ===\",\n",
    "            json_path.name,\n",
    "            len(run_ids),\n",
    "            total_epochs,\n",
    "        )\n",
    "        return run_ids, total_epochs\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Run checks\n",
    "# ------------------------------------------------------------\n",
    "def log_table_count(conn, table: str):\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        nb = cur.fetchone()[0]\n",
    "    logger.info(\"Table %s : %d ligne(s)\", table, nb)\n",
    "\n",
    "\n",
    "def run_checks_after_etl_luna(\n",
    "    json_path: Path,\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "):\n",
    "    run_ids, total_epochs = etl_luna_from_json_file(\n",
    "        json_path=json_path,\n",
    "        model_version=model_version,\n",
    "        training_tag=training_tag,\n",
    "    )\n",
    "\n",
    "    conn = get_conn()\n",
    "    try:\n",
    "        logger.info(\n",
    "            \"LUNA : %d run(s) créés/mis à jour, %d epochs insérés\",\n",
    "            len(run_ids),\n",
    "            total_epochs,\n",
    "        )\n",
    "\n",
    "        for tbl in [\"ai_model_run\", \"ai_epoch_prediction\"]:\n",
    "            log_table_count(conn, tbl)\n",
    "\n",
    "        if run_ids:\n",
    "            last_run = run_ids[-1]\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT *\n",
    "                    FROM ai_model_run\n",
    "                    WHERE run_id = %s\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\"Sample ai_model_run(last_run) : %s\", cur.fetchall())\n",
    "\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT epoch_index, onset_sec, duration_sec,\n",
    "                           predicted_stage_code,\n",
    "                           prob_w, prob_n1, prob_n2, prob_n3, prob_r\n",
    "                    FROM ai_epoch_prediction\n",
    "                    WHERE run_id = %s\n",
    "                    ORDER BY epoch_index\n",
    "                    LIMIT 10\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Sample ai_epoch_prediction(last_run, 10 premiers) : %s\",\n",
    "                    cur.fetchall(),\n",
    "                )\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Par défaut: predictions_luna_S0001.json\n",
    "    run_checks_after_etl_luna(DEFAULT_LUNA_JSON)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
