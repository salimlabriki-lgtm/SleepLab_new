{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bfdfc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 09:02:53,585 [INFO] sleeplab_etl_gssc - DB_DSN utilisé : postgresql://sleeplab:sleeplab@postgres:5432/sleeplab\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 0005_OUTPUT_GSSC_INTEGRATION.ipynb\n",
    "# ETL des prédictions GSSC vers les tables AI\n",
    "# ============================================================\n",
    "\n",
    "# %%\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import uuid\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "\n",
    "import psycopg2\n",
    "from psycopg2.extras import RealDictCursor\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 1. Logging\n",
    "# ------------------------------------------------------------\n",
    "logger = logging.getLogger(\"sleeplab_etl_gssc\")\n",
    "if not logger.handlers:\n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s [%(levelname)s] %(name)s - %(message)s\",\n",
    "    )\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 2. Config chemins & Postgres\n",
    "# ------------------------------------------------------------\n",
    "BASE_DIR = Path(\"/workspaces/SleepLab_new\").resolve()\n",
    "MODELS_OUTPUT_DIR = BASE_DIR / \"data\" / \"raw\" / \"MODELS_OUTPUT\"\n",
    "\n",
    "DEFAULT_GSSC_JSON = MODELS_OUTPUT_DIR / \"predictions_gssc_S0001.json\"\n",
    "\n",
    "DB_DSN = os.getenv(\n",
    "    \"SLEEPLAB_DB_DSN\",\n",
    "    \"postgresql://sleeplab:sleeplab@postgres:5432/sleeplab\",\n",
    ")\n",
    "\n",
    "logger.info(\"DB_DSN utilisé : %s\", DB_DSN)\n",
    "\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 3. Helpers Postgres locaux\n",
    "# ------------------------------------------------------------\n",
    "def get_conn():\n",
    "    conn = psycopg2.connect(DB_DSN)\n",
    "    with conn.cursor() as cur:\n",
    "        cur.execute(\"SET search_path TO sleeplab\")\n",
    "    conn.commit()\n",
    "    return conn\n",
    "\n",
    "\n",
    "def db_cursor(conn, dict_cursor: bool = False):\n",
    "    cursor_factory = RealDictCursor if dict_cursor else None\n",
    "    return conn.cursor(cursor_factory=cursor_factory)\n",
    "\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 4. Helpers métier : mapping session / run\n",
    "# ------------------------------------------------------------\n",
    "def require_file(path: Path, label: str) -> None:\n",
    "    if not path.exists():\n",
    "        logger.error(\"[FICHIER MANQUANT] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} non trouvé : {path}\")\n",
    "    if not path.is_file():\n",
    "        logger.error(\"[CHEMIN NON FICHIER] %s : %s\", label, path)\n",
    "        raise FileNotFoundError(f\"{label} n'est pas un fichier : {path}\")\n",
    "    logger.info(\"[OK] %s trouvé : %s\", label, path)\n",
    "\n",
    "\n",
    "def extract_subject_suffix_from_filename(json_path: Path) -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Ex: 'predictions_gssc_S0001.json' -> 'S0001'\n",
    "    \"\"\"\n",
    "    m = re.search(r\"_S(\\d{4})\\.json$\", json_path.name, re.IGNORECASE)\n",
    "    if not m:\n",
    "        logger.warning(\n",
    "            \"Impossible d'extraire un suffixe 'Sdddd' depuis le nom de fichier %s\",\n",
    "            json_path.name,\n",
    "        )\n",
    "        return None\n",
    "    suffix = f\"S{m.group(1)}\"\n",
    "    logger.info(\"Suffixe subject/session détecté à partir du nom de fichier : %s\", suffix)\n",
    "    return suffix\n",
    "\n",
    "\n",
    "def extract_session_code_from_edf_key(edf_key: str) -> str:\n",
    "    \"\"\"\n",
    "    Ex: 'PANDORE_SAS_DATASET_S0001_PSG.edf' -> 'PANDORE_SAS_DATASET_S0001'\n",
    "    \"\"\"\n",
    "    m = re.match(r\"^(?P<session_root>.+_S\\d{4})_PSG\\.edf$\", edf_key)\n",
    "    if not m:\n",
    "        raise ValueError(\n",
    "            f\"Impossible d'extraire session_root depuis la clé EDF '{edf_key}'\"\n",
    "        )\n",
    "    return m.group(\"session_root\")\n",
    "\n",
    "\n",
    "def get_session_id_from_code(conn, session_code: str) -> str:\n",
    "    with db_cursor(conn, dict_cursor=True) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT session_id\n",
    "            FROM study_session\n",
    "            WHERE session_code = %s\n",
    "            \"\"\",\n",
    "            (session_code,),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if not row:\n",
    "            raise RuntimeError(\n",
    "                f\"Aucune session trouvée pour session_code={session_code}\"\n",
    "            )\n",
    "        return row[\"session_id\"]\n",
    "\n",
    "\n",
    "def get_or_create_ai_model_run(\n",
    "    conn,\n",
    "    session_id: str,\n",
    "    model_name: str,\n",
    "    model_version: Optional[str],\n",
    "    training_tag: Optional[str],\n",
    "    source_file_name: str,\n",
    "    params_json: Optional[Dict[str, Any]] = None,\n",
    ") -> str:\n",
    "    version_key = model_version or \"\"\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            SELECT run_id\n",
    "            FROM ai_model_run\n",
    "            WHERE session_id = %s\n",
    "              AND model_name = %s\n",
    "              AND COALESCE(model_version,'') = %s\n",
    "              AND source_file_name = %s\n",
    "            \"\"\",\n",
    "            (session_id, model_name, version_key, source_file_name),\n",
    "        )\n",
    "        row = cur.fetchone()\n",
    "        if row:\n",
    "            run_id = row[0]\n",
    "            logger.info(\n",
    "                \"Run AI GSSC déjà présent (session_id=%s, model=%s, version=%s, src=%s) → run_id=%s\",\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                source_file_name,\n",
    "                run_id,\n",
    "            )\n",
    "            return run_id\n",
    "\n",
    "        run_id = str(uuid.uuid4())\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO ai_model_run (\n",
    "                run_id, session_id,\n",
    "                model_name, model_version,\n",
    "                training_tag, source_file_name,\n",
    "                params_json, created_ts\n",
    "            )\n",
    "            VALUES (%s,%s,%s,%s,%s,%s,%s, NOW())\n",
    "            \"\"\",\n",
    "            (\n",
    "                run_id,\n",
    "                session_id,\n",
    "                model_name,\n",
    "                model_version,\n",
    "                training_tag,\n",
    "                source_file_name,\n",
    "                json.dumps(params_json) if params_json is not None else None,\n",
    "            ),\n",
    "        )\n",
    "        logger.info(\n",
    "            \"Nouveau run AI GSSC inséré : run_id=%s (model=%s, version=%s, session_id=%s)\",\n",
    "            run_id,\n",
    "            model_name,\n",
    "            model_version,\n",
    "            session_id,\n",
    "        )\n",
    "        return run_id\n",
    "\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 5. Mapping des labels GSSC\n",
    "# ------------------------------------------------------------\n",
    "# Hypothèse standard GSSC :\n",
    "#   0 → W, 1 → N1, 2 → N2, 3 → N3, 4 → R\n",
    "GSSC_LABEL_TO_STAGE = {\n",
    "    0: \"W\",\n",
    "    1: \"N1\",\n",
    "    2: \"N2\",\n",
    "    3: \"N3\",\n",
    "    4: \"R\",\n",
    "}\n",
    "\n",
    "\n",
    "def gssc_label_int_to_stage(label: int) -> Optional[str]:\n",
    "    stage = GSSC_LABEL_TO_STAGE.get(label)\n",
    "    if stage is None:\n",
    "        logger.warning(\"Label GSSC inattendu : %s\", label)\n",
    "    return stage\n",
    "\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 6. ETL principal GSSC\n",
    "# ------------------------------------------------------------\n",
    "def etl_gssc_from_json_file(\n",
    "    json_path: Path,\n",
    "    model_name: str = \"GSSC\",\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "    default_epoch_length_sec: int = 30,\n",
    ") -> Tuple[List[str], int]:\n",
    "    \"\"\"\n",
    "    Intègre un JSON GSSC dans ai_model_run + ai_epoch_prediction.\n",
    "\n",
    "    Structure attendue (par EDF) :\n",
    "      {\n",
    "        \"PANDORE_SAS_DATASET_S0001_PSG.edf\": {\n",
    "          \"infos\": {...},\n",
    "          \"prediction\": [0, 0, 1, 2, ...],\n",
    "          \"timestamps\": [0.0, 30.0, 60.0, ...]\n",
    "        },\n",
    "        ...\n",
    "      }\n",
    "    \"\"\"\n",
    "    require_file(json_path, f\"JSON GSSC {model_name}\")\n",
    "    suffix = extract_subject_suffix_from_filename(json_path)\n",
    "\n",
    "    logger.info(\"=== ETL GSSC démarré pour %s ===\", json_path.name)\n",
    "    raw_text = json_path.read_text()\n",
    "    data = json.loads(raw_text)\n",
    "\n",
    "    if not isinstance(data, dict):\n",
    "        raise ValueError(f\"Structure JSON inattendue (top-level) : {type(data)}\")\n",
    "\n",
    "    conn = get_conn()\n",
    "    run_ids: List[str] = []\n",
    "    total_epochs = 0\n",
    "\n",
    "    try:\n",
    "        with conn:\n",
    "            for edf_key, payload in data.items():\n",
    "                logger.info(\"Traitement de la clé EDF : %s\", edf_key)\n",
    "\n",
    "                session_code = extract_session_code_from_edf_key(edf_key)\n",
    "                logger.info(\"session_code dérivé de la clé EDF : %s\", session_code)\n",
    "\n",
    "                if suffix and suffix.lower() not in session_code.lower():\n",
    "                    logger.warning(\n",
    "                        \"Le suffixe '%s' (depuis le nom du fichier JSON) \"\n",
    "                        \"ne correspond pas au session_code '%s' (clé EDF).\",\n",
    "                        suffix,\n",
    "                        session_code,\n",
    "                    )\n",
    "\n",
    "                session_id = get_session_id_from_code(conn, session_code)\n",
    "\n",
    "                if not isinstance(payload, dict):\n",
    "                    logger.warning(\n",
    "                        \"Payload GSSC inattendu pour %s (type=%s) → ignoré\",\n",
    "                        edf_key,\n",
    "                        type(payload),\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                preds = payload.get(\"prediction\")\n",
    "                stamps = payload.get(\"timestamps\")\n",
    "\n",
    "                if preds is None or stamps is None:\n",
    "                    logger.warning(\n",
    "                        \"Prediction ou timestamps manquants pour %s → ignoré\", edf_key\n",
    "                    )\n",
    "                    continue\n",
    "\n",
    "                if len(preds) != len(stamps):\n",
    "                    logger.warning(\n",
    "                        \"Longueur preds (%d) != timestamps (%d) pour %s. \"\n",
    "                        \"On utilisera min(n_preds, n_timestamps).\",\n",
    "                        len(preds),\n",
    "                        len(stamps),\n",
    "                        edf_key,\n",
    "                    )\n",
    "                n = min(len(preds), len(stamps))\n",
    "\n",
    "                infos = payload.get(\"infos\", {})\n",
    "                params_json = {\n",
    "                    \"source_edf_key\": edf_key,\n",
    "                    \"model_info\": infos,\n",
    "                    \"notes\": \"GSSC predictions imported from JSON\",\n",
    "                }\n",
    "\n",
    "                run_id = get_or_create_ai_model_run(\n",
    "                    conn,\n",
    "                    session_id=session_id,\n",
    "                    model_name=model_name,\n",
    "                    model_version=model_version,\n",
    "                    training_tag=training_tag,\n",
    "                    source_file_name=json_path.name,\n",
    "                    params_json=params_json,\n",
    "                )\n",
    "                run_ids.append(run_id)\n",
    "\n",
    "                # Nettoyage préalable\n",
    "                with db_cursor(conn) as cur:\n",
    "                    cur.execute(\n",
    "                        \"DELETE FROM ai_epoch_prediction WHERE run_id = %s\",\n",
    "                        (run_id,),\n",
    "                    )\n",
    "                    nb_deleted = cur.rowcount\n",
    "                if nb_deleted:\n",
    "                    logger.info(\n",
    "                        \"%d prédiction(s) GSSC existante(s) supprimée(s) pour run_id=%s\",\n",
    "                        nb_deleted,\n",
    "                        run_id,\n",
    "                    )\n",
    "\n",
    "                # Insertion\n",
    "                inserted = 0\n",
    "                with db_cursor(conn) as cur:\n",
    "                    for idx in range(n):\n",
    "                        label = preds[idx]\n",
    "                        ts = stamps[idx]\n",
    "\n",
    "                        try:\n",
    "                            int_label = int(label)\n",
    "                        except Exception:\n",
    "                            logger.warning(\n",
    "                                \"Label non entier à l'index %d : %s\", idx, label\n",
    "                            )\n",
    "                            continue\n",
    "\n",
    "                        stage = gssc_label_int_to_stage(int_label)\n",
    "\n",
    "                        # onset_sec : on privilégie timestamps GSSC, sinon idx*epoch_length\n",
    "                        try:\n",
    "                            onset_sec = float(ts)\n",
    "                        except Exception:\n",
    "                            onset_sec = float(idx * default_epoch_length_sec)\n",
    "\n",
    "                        # duration_sec : on approxime par différence de timestamps\n",
    "                        if idx < n - 1:\n",
    "                            try:\n",
    "                                duration_sec = float(stamps[idx + 1]) - float(ts)\n",
    "                            except Exception:\n",
    "                                duration_sec = float(default_epoch_length_sec)\n",
    "                        else:\n",
    "                            duration_sec = float(default_epoch_length_sec)\n",
    "\n",
    "                        extra_json = {\n",
    "                            \"gssc_label_int\": int_label,\n",
    "                            \"timestamp_raw\": ts,\n",
    "                        }\n",
    "\n",
    "                        epoch_pred_id = str(uuid.uuid4())\n",
    "                        cur.execute(\n",
    "                            \"\"\"\n",
    "                            INSERT INTO ai_epoch_prediction (\n",
    "                                epoch_pred_id, run_id,\n",
    "                                epoch_index, onset_sec, duration_sec,\n",
    "                                predicted_stage_code,\n",
    "                                prob_w, prob_n1, prob_n2, prob_n3, prob_r,\n",
    "                                extra_json\n",
    "                            )\n",
    "                            VALUES (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\n",
    "                            \"\"\",\n",
    "                            (\n",
    "                                epoch_pred_id,\n",
    "                                run_id,\n",
    "                                int(idx),\n",
    "                                onset_sec,\n",
    "                                duration_sec,\n",
    "                                stage,\n",
    "                                None,  # prob_w\n",
    "                                None,  # prob_n1\n",
    "                                None,  # prob_n2\n",
    "                                None,  # prob_n3\n",
    "                                None,  # prob_r\n",
    "                                json.dumps(extra_json),\n",
    "                            ),\n",
    "                        )\n",
    "                        inserted += 1\n",
    "\n",
    "                logger.info(\n",
    "                    \"GSSC : %d prédiction(s) epoch insérées pour run_id=%s\",\n",
    "                    inserted,\n",
    "                    run_id,\n",
    "                )\n",
    "                total_epochs += inserted\n",
    "\n",
    "        logger.info(\n",
    "            \"=== ETL GSSC terminé pour %s : runs=%d, epochs=%d ===\",\n",
    "            json_path.name,\n",
    "            len(run_ids),\n",
    "            total_epochs,\n",
    "        )\n",
    "        return run_ids, total_epochs\n",
    "\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "\n",
    "# %%\n",
    "# ------------------------------------------------------------\n",
    "# 7. Fonction de contrôle : run_checks_after_etl_gssc\n",
    "# ------------------------------------------------------------\n",
    "def log_table_count(conn, table: str):\n",
    "    with db_cursor(conn) as cur:\n",
    "        cur.execute(f\"SELECT COUNT(*) FROM {table}\")\n",
    "        nb = cur.fetchone()[0]\n",
    "    logger.info(\"Table %s : %d ligne(s)\", table, nb)\n",
    "\n",
    "\n",
    "def run_checks_after_etl_gssc(\n",
    "    json_path: Path,\n",
    "    model_version: Optional[str] = None,\n",
    "    training_tag: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Lance l'ETL GSSC puis affiche quelques stats / échantillons.\n",
    "    \"\"\"\n",
    "    run_ids, total_epochs = etl_gssc_from_json_file(\n",
    "        json_path=json_path,\n",
    "        model_version=model_version,\n",
    "        training_tag=training_tag,\n",
    "    )\n",
    "\n",
    "    conn = get_conn()\n",
    "    try:\n",
    "        logger.info(\"GSSC : %d run(s) créés/mis à jour, %d epochs insérés\", len(run_ids), total_epochs)\n",
    "\n",
    "        for tbl in [\"ai_model_run\", \"ai_epoch_prediction\"]:\n",
    "            log_table_count(conn, tbl)\n",
    "\n",
    "        if run_ids:\n",
    "            last_run = run_ids[-1]\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT *\n",
    "                    FROM ai_model_run\n",
    "                    WHERE run_id = %s\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\"Sample ai_model_run(last_run) : %s\", cur.fetchall())\n",
    "\n",
    "            with db_cursor(conn, dict_cursor=True) as cur:\n",
    "                cur.execute(\n",
    "                    \"\"\"\n",
    "                    SELECT epoch_index, onset_sec, duration_sec,\n",
    "                           predicted_stage_code\n",
    "                    FROM ai_epoch_prediction\n",
    "                    WHERE run_id = %s\n",
    "                    ORDER BY epoch_index\n",
    "                    LIMIT 10\n",
    "                    \"\"\",\n",
    "                    (last_run,),\n",
    "                )\n",
    "                logger.info(\n",
    "                    \"Sample ai_epoch_prediction(last_run, 10 premiers) : %s\",\n",
    "                    cur.fetchall(),\n",
    "                )\n",
    "    finally:\n",
    "        conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7d9b896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 09:03:01,015 [INFO] sleeplab_etl_gssc - [OK] JSON GSSC GSSC trouvé : /workspaces/SleepLab_new/data/raw/MODELS_OUTPUT/predictions_gssc_S0001.json\n",
      "2025-12-08 09:03:01,018 [INFO] sleeplab_etl_gssc - Suffixe subject/session détecté à partir du nom de fichier : S0001\n",
      "2025-12-08 09:03:01,018 [INFO] sleeplab_etl_gssc - === ETL GSSC démarré pour predictions_gssc_S0001.json ===\n",
      "2025-12-08 09:03:01,034 [INFO] sleeplab_etl_gssc - Traitement de la clé EDF : PANDORE_SAS_DATASET_S0001_PSG.edf\n",
      "2025-12-08 09:03:01,035 [INFO] sleeplab_etl_gssc - session_code dérivé de la clé EDF : PANDORE_SAS_DATASET_S0001\n",
      "2025-12-08 09:03:01,039 [INFO] sleeplab_etl_gssc - Nouveau run AI GSSC inséré : run_id=161cc47e-6345-4875-bfd5-a1754a20445f (model=GSSC, version=v1, session_id=0ee866aa-e9db-4af5-bc70-89e99827d320)\n",
      "2025-12-08 09:03:01,269 [INFO] sleeplab_etl_gssc - GSSC : 1245 prédiction(s) epoch insérées pour run_id=161cc47e-6345-4875-bfd5-a1754a20445f\n",
      "2025-12-08 09:03:01,273 [INFO] sleeplab_etl_gssc - === ETL GSSC terminé pour predictions_gssc_S0001.json : runs=1, epochs=1245 ===\n",
      "2025-12-08 09:03:01,287 [INFO] sleeplab_etl_gssc - GSSC : 1 run(s) créés/mis à jour, 1245 epochs insérés\n",
      "2025-12-08 09:03:01,289 [INFO] sleeplab_etl_gssc - Table ai_model_run : 2 ligne(s)\n",
      "2025-12-08 09:03:01,291 [INFO] sleeplab_etl_gssc - Table ai_epoch_prediction : 2490 ligne(s)\n",
      "2025-12-08 09:03:01,292 [INFO] sleeplab_etl_gssc - Sample ai_model_run(last_run) : [RealDictRow({'run_id': '161cc47e-6345-4875-bfd5-a1754a20445f', 'session_id': '0ee866aa-e9db-4af5-bc70-89e99827d320', 'model_name': 'GSSC', 'model_version': 'v1', 'training_tag': None, 'source_file_name': 'predictions_gssc_S0001.json', 'params_json': {'notes': 'GSSC predictions imported from JSON', 'model_info': {'chs': [{'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 1, 'range': 1.0, 'scanno': 1, 'ch_name': 'Activity', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 2, 'range': 1.0, 'scanno': 2, 'ch_name': 'c3-0', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 3, 'range': 1.0, 'scanno': 3, 'ch_name': 'c3-1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 4, 'range': 1.0, 'scanno': 4, 'ch_name': 'C4-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 5, 'range': 1.0, 'scanno': 5, 'ch_name': 'C4', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 6, 'range': 1.0, 'scanno': 6, 'ch_name': 'f3-0', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 7, 'range': 1.0, 'scanno': 7, 'ch_name': 'f3-1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 8, 'range': 1.0, 'scanno': 8, 'ch_name': 'F4-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 9, 'range': 1.0, 'scanno': 9, 'ch_name': 'F4', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 10, 'range': 1.0, 'scanno': 10, 'ch_name': 'M1M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 11, 'range': 1.0, 'scanno': 11, 'ch_name': 'M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 12, 'range': 1.0, 'scanno': 12, 'ch_name': 'M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 13, 'range': 1.0, 'scanno': 13, 'ch_name': 'O1-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 14, 'range': 1.0, 'scanno': 14, 'ch_name': 'O1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 15, 'range': 1.0, 'scanno': 15, 'ch_name': 'O2-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 16, 'range': 1.0, 'scanno': 16, 'ch_name': 'O2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 17, 'range': 1.0, 'scanno': 17, 'ch_name': '1-2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 18, 'range': 1.0, 'scanno': 18, 'ch_name': '1-F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 19, 'range': 1.0, 'scanno': 19, 'ch_name': '1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 20, 'range': 1.0, 'scanno': 20, 'ch_name': '2-F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 21, 'range': 1.0, 'scanno': 21, 'ch_name': '2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 22, 'range': 1.0, 'scanno': 22, 'ch_name': 'F', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 23, 'range': 1.0, 'scanno': 23, 'ch_name': 'Left Leg', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 24, 'range': 1.0, 'scanno': 24, 'ch_name': 'Right Leg', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 25, 'range': 1.0, 'scanno': 25, 'ch_name': 'E1-M2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 26, 'range': 1.0, 'scanno': 26, 'ch_name': 'E1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 27, 'range': 1.0, 'scanno': 27, 'ch_name': 'E2-M1', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 28, 'range': 1.0, 'scanno': 28, 'ch_name': 'E2', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 29, 'range': 1.0, 'scanno': 29, 'ch_name': 'Heart Rate', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 30, 'range': 1.0, 'scanno': 30, 'ch_name': 'Light', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 31, 'range': 1.0, 'scanno': 31, 'ch_name': 'PosAngle', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 32, 'range': 1.0, 'scanno': 32, 'ch_name': 'Pulse', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 33, 'range': 1.0, 'scanno': 33, 'ch_name': 'Flow Limitation', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 34, 'range': 1.0, 'scanno': 34, 'ch_name': 'Airflow', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 35, 'range': 1.0, 'scanno': 35, 'ch_name': 'RIP Flow', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 36, 'range': 1.0, 'scanno': 36, 'ch_name': 'RIP Flow Cal', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 37, 'range': 1.0, 'scanno': 37, 'ch_name': 'Inductance Abdom', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 38, 'range': 1.0, 'scanno': 38, 'ch_name': 'Inductance Thora', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 39, 'range': 1.0, 'scanno': 39, 'ch_name': 'K', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 40, 'range': 1.0, 'scanno': 40, 'ch_name': 'Abdomen RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 41, 'range': 1.0, 'scanno': 41, 'ch_name': 'Thorax RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 42, 'range': 1.0, 'scanno': 42, 'ch_name': 'Phase RIP', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 43, 'range': 1.0, 'scanno': 43, 'ch_name': 'Nasal Pressure', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 44, 'range': 1.0, 'scanno': 44, 'ch_name': 'Resp Rate', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}, {'cal': 1.0, 'loc': '[nan nan nan nan nan nan nan nan nan nan nan nan]', 'kind': 2, 'unit': 107, 'logno': 45, 'range': 1.0, 'scanno': 45, 'ch_name': 'Snoring', 'unit_mul': 0, 'coil_type': 1, 'coord_frame': 4}], 'dig': None, 'bads': [], 'comps': [], 'nchan': 45, 'projs': [], 'sfreq': 200.0, 'events': [], 'file_id': None, 'lowpass': 30.0, 'meas_id': None, 'proj_id': None, 'acq_pars': None, 'acq_stim': None, 'ch_names': ['Activity', 'c3-0', 'c3-1', 'C4-M1', 'C4', 'f3-0', 'f3-1', 'F4-M1', 'F4', 'M1M2', 'M1', 'M2', 'O1-M2', 'O1', 'O2-M1', 'O2', '1-2', '1-F', '1', '2-F', '2', 'F', 'Left Leg', 'Right Leg', 'E1-M2', 'E1', 'E2-M1', 'E2', 'Heart Rate', 'Light', 'PosAngle', 'Pulse', 'Flow Limitation', 'Airflow', 'RIP Flow', 'RIP Flow Cal', 'Inductance Abdom', 'Inductance Thora', 'K', 'Abdomen RIP', 'Thorax RIP', 'Phase RIP', 'Nasal Pressure', 'Resp Rate', 'Snoring'], 'highpass': 0.3, 'hpi_meas': [], 'dev_ctf_t': None, 'line_freq': None, 'meas_date': '2001-01-01T22:00:08+00:00', 'proj_name': None, 'ctf_head_t': None, 'dev_head_t': {'to': 4, 'from': 1, 'trans': '[[1. 0. 0. 0.]\\n [0. 1. 0. 0.]\\n [0. 0. 1. 0.]\\n [0. 0. 0. 1.]]'}, 'utc_offset': None, 'description': None, 'device_info': None, 'helium_info': None, 'hpi_results': [], 'experimenter': None, 'gantry_angle': None, 'proc_history': [], 'subject_info': {'sex': 0, 'his_id': 'X', 'last_name': 'X'}, 'hpi_subsystem': None, 'kit_system_id': None, 'xplotter_layout': None, 'custom_ref_applied': 0}, 'source_edf_key': 'PANDORE_SAS_DATASET_S0001_PSG.edf'}, 'run_ts': datetime.datetime(2025, 12, 8, 9, 3, 1, 36287, tzinfo=datetime.timezone.utc), 'created_ts': datetime.datetime(2025, 12, 8, 9, 3, 1, 36287, tzinfo=datetime.timezone.utc)})]\n",
      "2025-12-08 09:03:01,295 [INFO] sleeplab_etl_gssc - Sample ai_epoch_prediction(last_run, 10 premiers) : [RealDictRow({'epoch_index': 0, 'onset_sec': Decimal('0.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 1, 'onset_sec': Decimal('30.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 2, 'onset_sec': Decimal('60.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 3, 'onset_sec': Decimal('90.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 4, 'onset_sec': Decimal('120.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 5, 'onset_sec': Decimal('150.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 6, 'onset_sec': Decimal('180.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 7, 'onset_sec': Decimal('210.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 8, 'onset_sec': Decimal('240.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'}), RealDictRow({'epoch_index': 9, 'onset_sec': Decimal('270.000'), 'duration_sec': Decimal('30.000'), 'predicted_stage_code': 'W'})]\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# Exemple d'appel dans le notebook :\n",
    "from pathlib import Path\n",
    "gssc_json = MODELS_OUTPUT_DIR / \"predictions_gssc_S0001.json\"\n",
    "run_checks_after_etl_gssc(json_path=gssc_json, model_version=\"v1\", training_tag=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_sleeplab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
